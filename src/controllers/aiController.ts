import { Request, Response } from "express";

// Service de fallback avec r√©ponses intelligentes
const getFallbackResponse = (userMessage: string, modelData: any): string => {
    const message = userMessage.toLowerCase();

    // R√©ponses contextuelles bas√©es sur le message
    if (message.includes("bonjour") || message.includes("salut") || message.includes("coucou")) {
        return modelData
            ? `Enchant√© ! Je suis ${modelData.prenom}, comment vas-tu aujourd'hui ?`
            : "Enchant√© ! Comment vas-tu aujourd'hui ?";
    }

    if (message.includes("√ßa va") || message.includes("comment vas-tu")) {
        return "Je vais tr√®s bien, merci de demander ! Et toi, comment se passe ta journ√©e ?";
    }

    if (message.includes("pr√©nom") || message.includes("appelles") || message.includes("nom")) {
        return modelData
            ? `Je m'appelle ${modelData.prenom}, ravi de faire ta connaissance !`
            : "Je suis ton compagnon virtuel, ravi de faire ta connaissance !";
    }

    if (message.includes("√¢ge") || message.includes("vie")) {
        return modelData
            ? `J'ai ${modelData.age} ans, et toi ?`
            : "Je suis un √™tre virtuel √©ternellement jeune, et toi ?";
    }

    if (message.includes("hobby") || message.includes("passe-temps") || message.includes("loisir")) {
        return modelData
            ? `J'adore ${modelData.passe_temps.toLowerCase()}. Qu'est-ce qui te passionne toi ?`
            : "J'adore discuter avec des personnes int√©ressantes comme toi. Et toi, qu'est-ce qui te passionne ?";
    }

    if (message.includes("habites") || message.includes("ville") || message.includes("o√π")) {
        return modelData
            ? `Je vis √† ${modelData.domicile}, une ville magnifique ! Et toi, tu es d'o√π ?`
            : "Je vis dans le monde virtuel, mais j'adore d√©couvrir de nouveaux endroits. Et toi, tu es d'o√π ?";
    }

    if (message.includes("citation") || message.includes("phrase") || message.includes("pr√©f√©r√©e")) {
        return modelData
            ? `Ma citation pr√©f√©r√©e est : "${modelData.citation}". Qu'en penses-tu ?`
            : "J'aime beaucoup cette citation : 'La vie est un myst√®re qu'il faut vivre, et non un probl√®me √† r√©soudre'. Qu'en penses-tu ?";
    }

    // R√©ponses g√©n√©riques
    const genericResponses = [
        "Int√©ressant ! Dis-m'en plus üí´",
        "Je vois ce que tu veux dire... Continue ‚ú®",
        "C'est fascinant ! Raconte-moi plus sur √ßa",
        "J'adore apprendre de nouvelles choses. Peux-tu d√©velopper ?",
        "Tr√®s bien dit üëç J'aimerais en savoir plus",
        "C'est une perspective int√©ressante. Comment en es-tu arriv√© l√† ?",
        "Je comprends tout √† fait. Que penses-tu de cela ?",
        "C'est vraiment int√©ressant ! Comment te sens-tu par rapport √† √ßa ?",
        "Je vois. Et si on parlait de tes passions ?",
        "C'est captivant ! Y a-t-il autre chose que tu aimerais partager ?"
    ];

    return genericResponses[Math.floor(Math.random() * genericResponses.length)];
};

// API gratuite - DeepSeek Chat (gratuit)
const tryDeepSeekAPI = async (message: string, history: any[]): Promise<string | null> => {
    try {
        const response = await fetch("https://api.deepseek.com/v1/chat/completions", {
            method: "POST",
            headers: {
                "Content-Type": "application/json",
            },
            body: JSON.stringify({
                model: "deepseek-chat",
                messages: [
                    {
                        role: "system",
                        content: "Tu es un assistant conversationnel sympathique et utile. R√©ponds de mani√®re naturelle et engageante."
                    },
                    ...history,
                    { role: "user", content: message }
                ],
                max_tokens: 150,
                temperature: 0.7,
            }),
            timeout: 10000 // Timeout de 10 secondes
        });

        if (response.ok) {
            const data = await response.json();
            return data.choices[0]?.message?.content || null;
        }
        return null;
    } catch (error) {
        console.log("DeepSeek API non disponible, utilisation du fallback");
        return null;
    }
};

// API gratuite - Hugging Face Inference API (gratuit)
const tryHuggingFaceAPI = async (message: string): Promise<string | null> => {
    try {
        const response = await fetch(
            "https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium",
            {
                method: "POST",
                headers: {
                    "Content-Type": "application/json",
                },
                body: JSON.stringify({
                    inputs: message,
                    parameters: {
                        max_length: 100,
                        temperature: 0.7
                    }
                }),
                timeout: 10000
            }
        );

        if (response.ok) {
            const data = await response.json();
            return data.generated_text || null;
        }
        return null;
    } catch (error) {
        console.log("Hugging Face API non disponible");
        return null;
    }
};

export const chatWithAI = async (req: Request, res: Response) => {
    try {
        const { message, history, modelData } = req.body;

        // V√©rifier que le message est pr√©sent
        if (!message) {
            return res.status(400).json({
                success: false,
                error: "Le message est requis"
            });
        }

        let reply: string;
        let usedAPI = "fallback";

        // Essayer d'abord DeepSeek (gratuit)
        const deepSeekReply = await tryDeepSeekAPI(message, history || []);
        if (deepSeekReply) {
            reply = deepSeekReply;
            usedAPI = "deepseek";
        } else {
            // Essayer Hugging Face en backup
            const huggingFaceReply = await tryHuggingFaceAPI(message);
            if (huggingFaceReply) {
                reply = huggingFaceReply;
                usedAPI = "huggingface";
            } else {
                // Fallback vers nos r√©ponses intelligentes
                reply = getFallbackResponse(message, modelData);
                usedAPI = "fallback";
            }
        }

        // Simulation du temps de r√©ponse r√©aliste
        const delay = Math.random() * 800 + 400;

        setTimeout(() => {
            res.status(200).json({
                success: true,
                reply,
                timestamp: new Date().toISOString(),
                source: usedAPI
            });
        }, delay);

    } catch (error) {
        console.error("Erreur dans le contr√¥leur AI:", error);

        // Fallback garanti en cas d'erreur
        const fallbackReply = getFallbackResponse(
            req.body.message || "Bonjour",
            req.body.modelData
        );

        res.status(200).json({
            success: true,
            reply: fallbackReply,
            source: "fallback-error",
            timestamp: new Date().toISOString()
        });
    }
};